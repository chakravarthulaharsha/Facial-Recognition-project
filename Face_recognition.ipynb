{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqJhtx1MdBr2"
      },
      "outputs": [],
      "source": [
        "# pip installing\n",
        "!pip install tensorflow opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GLjDpv5LdBsB"
      },
      "outputs": [],
      "source": [
        "# Import standard dependencies\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# Import tensorflow dependencies - Functional API\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf\n",
        "import uuid\n",
        "from tensorflow.keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "print(gpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfsNANlOr3Uu",
        "outputId": "f5155942-b5f4-44a1-825b-a991175e3115"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MabyhvubmZ1T",
        "outputId": "0bb47466-8f8a-43ec-9feb-72fc2d062ba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gxY09SFjdBsD"
      },
      "outputs": [],
      "source": [
        "# Setup paths\n",
        "path='/content/drive/MyDrive/FaceRecognition-main'\n",
        "POS_PATH = os.path.join(path, 'positive')\n",
        "NEG_PATH = os.path.join(path, 'negative')\n",
        "ANC_PATH = os.path.join(path, 'anchor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IsEmVrBxdBsF"
      },
      "outputs": [],
      "source": [
        "# Make the directories\n",
        "if(not os.path.isdir(path +'//positive')):\n",
        "    os.makedirs(POS_PATH)\n",
        "if(not os.path.isdir(path +'//negative')):\n",
        "    os.makedirs(NEG_PATH)\n",
        "if(not os.path.isdir(path +'//anchor')):\n",
        "    os.makedirs(ANC_PATH)\n",
        "if(not os.path.isdir(path+'//training_checkpoints')):\n",
        "    os.makedirs(path+'//training_checkpoints')\n",
        "if(not os.path.isdir(path+'//application_data')):\n",
        "    os.makedirs(path+'//application_data')\n",
        "if(not os.path.isdir(path+'//images')):\n",
        "    os.makedirs(path+'//images')\n",
        "if(not os.path.isdir(path+'//application_data'+'//input_image')):\n",
        "    os.makedirs(path+'//application_data'+'//input_image')\n",
        "if(not os.path.isdir(path+'//application_data'+'//verification_image')):\n",
        "    os.makedirs(path+'//application_data'+'//verification_image')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DtDqAAlZdBsH",
        "outputId": "6506dbe6-1abf-4d9a-d2ee-c8de858681b0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b120fd0a78d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mEX_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lfw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mNEW_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEG_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEX_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNEW_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for directory in os.listdir(os.path.join(path, 'lfw')):\n",
        "  for file in os.listdir(os.path.join(os.path.join(path, 'lfw'), directory)):\n",
        "    EX_PATH = os.path.join(os.path.join(path, 'lfw'), directory, file)\n",
        "    NEW_PATH = os.path.join(NEG_PATH, file)\n",
        "    os.replace(EX_PATH, NEW_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DD63W6LDdBsI"
      },
      "outputs": [],
      "source": [
        "# Dummy input\n",
        "user_name='Harsha'\n",
        "USR_ANC = os.path.join(ANC_PATH, user_name)\n",
        "USR_POS= os.path.join(POS_PATH, user_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0EA67YhdBsL"
      },
      "outputs": [],
      "source": [
        "# user_name=input(\"Enter Username :\")\n",
        "\n",
        "# while(os.path.isdir(os.path.join(path ,'positive', user_name))):\n",
        "#     print(\"User name already exists, Choose different username\")\n",
        "#     user_name=input(\"Enter Username :\")\n",
        "\n",
        "\n",
        "# os.makedirs(os.path.join(POS_PATH, user_name))\n",
        "# os.makedirs(os.path.join(ANC_PATH, user_name))\n",
        "# USR_ANC = os.path.join(ANC_PATH, user_name)\n",
        "# USR_POS= os.path.join(POS_PATH, user_name)\n",
        "\n",
        "# video = cv2.VideoCapture(0)\n",
        "\n",
        "# i = 0\n",
        "\n",
        "# while(True):\n",
        "#     i = i+1\n",
        "#     ret, frame = video.read()\n",
        "#     frame =frame[120:370,200:450,:] \n",
        "#     if cv2.waitKey(1) & 0xFF == ord('a'):\n",
        "#         imgname=os.path.join(ANC_PATH , user_name,'{}.jpg'.format(uuid.uuid1()))\n",
        "#         cv2.imwrite(imgname,frame)\n",
        "#     if cv2.waitKey(1) & 0xFF == ord('p'):\n",
        "#         imgname=os.path.join(POS_PATH , user_name,'{}.jpg'.format(uuid.uuid1()))\n",
        "#         cv2.imwrite(imgname,frame)\n",
        "#     cv2.imshow('Validation', frame)\n",
        "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         break\n",
        "\n",
        "# video.release()\n",
        "# cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AwJ193CBdBsN"
      },
      "outputs": [],
      "source": [
        "anchor= tf.data.Dataset.list_files(USR_ANC+'/*.jpg').take(400)\n",
        "positive= tf.data.Dataset.list_files(USR_POS+'/*.jpg').take(400)\n",
        "negative= tf.data.Dataset.list_files (NEG_PATH+'/*.jpg').take(400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HUYIdc6WdBsO"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path):\n",
        "    img_byte = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(img_byte)\n",
        "    img = tf.image.resize(img,(100,100))\n",
        "    img = img / 255.0\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LEa5fKWHdBsQ"
      },
      "outputs": [],
      "source": [
        "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
        "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
        "data=positives.concatenate(negatives)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g8paJh89dBsR"
      },
      "outputs": [],
      "source": [
        "def preprocess_twin(img_input, img_validation, label):\n",
        "    return (preprocess(img_input), preprocess(img_validation), label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8VsjC8gCdBsS"
      },
      "outputs": [],
      "source": [
        "data = data.map(preprocess_twin)\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mt6sA2oPdBsT"
      },
      "outputs": [],
      "source": [
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)\n",
        "train_data = train_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yAsUpIiEdBsU"
      },
      "outputs": [],
      "source": [
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)\n",
        "test_data = test_data.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PHV1KyYMdBsV"
      },
      "outputs": [],
      "source": [
        "def make_embed():\n",
        "    inp = Input(shape=(100,100,3),name='input_image')\n",
        "    \n",
        "    c1= Conv2D(64, (10,10), activation = 'relu')(inp)\n",
        "    m1 = MaxPooling2D(64,(2,2), padding = 'same')(c1)\n",
        "    \n",
        "    c2= Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2) , padding = 'same')(c2)\n",
        "    \n",
        "    c3= Conv2D(128 , (4,4) , activation='relu')(m2)\n",
        "    m3=MaxPooling2D(64, (2,2), padding = 'same')(c3)\n",
        "    \n",
        "    c4= Conv2D(256 , (4,4) , activation='relu')(m3)\n",
        "    f1= Flatten()(c4)\n",
        "    d1= Dense(4096, activation='sigmoid')(f1)\n",
        "    \n",
        "    return Model(inputs=[inp] , outputs=[d1] , name='embedding')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iyFMj-ETdBsW"
      },
      "outputs": [],
      "source": [
        "embed = make_embed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fzjCnDT4dBsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229e63ae-b65d-4120-da2f-16de248b0574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              37752832  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,960,448\n",
            "Trainable params: 38,960,448\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embed.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qlOtYYkIdBsY"
      },
      "outputs": [],
      "source": [
        "class L1Dist(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "    \n",
        "    \n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TBtz9sIRdBsZ"
      },
      "outputs": [],
      "source": [
        "def make_siamese_model():\n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "    \n",
        "    validation_image= Input(name='validation_img', shape=(100,100,3))\n",
        "    \n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances= siamese_layer(embed(input_image),embed(validation_image))\n",
        "    \n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "    return Model(inputs=[input_image, validation_image],outputs=classifier,name='SiameseNetwork')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7JEQxSU2dBsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a2a172-1dcc-4a70-fbda-7e4c41e52657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SiameseNetwork\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
            "                                                                  'validation_img[0][0]']         \n",
            "                                                                                                  \n",
            " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "siam_model=make_siamese_model()\n",
        "siam_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jLLPGoAwdBsb"
      },
      "outputs": [],
      "source": [
        "binary_cross_loss=tf.losses.BinaryCrossentropy()\n",
        "opt = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "S6NOYOUwdBsc"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = path+'//training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siam_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e0IwbAuLdBsc"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        X=batch[:2]\n",
        "        y= batch[2]\n",
        "        \n",
        "        yhat = siam_model(X, training=True)\n",
        "        loss=binary_cross_loss(y, yhat)\n",
        "        \n",
        "    grad = tape.gradient(loss, siam_model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grad, siam_model.trainable_variables))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jxmH4YUDdBsd"
      },
      "outputs": [],
      "source": [
        "def train(data , EPOCHS):\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch,EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "        for idx, batch in enumerate(data):\n",
        "            train_step(batch)\n",
        "            progbar.update(idx+1)\n",
        "        if epoch % 10 == 0:\n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vTFlzALMdBsd"
      },
      "outputs": [],
      "source": [
        "EPOCHS=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RZpr3BAedBse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863abcc8-f40f-4251-ea40-408d6c434d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/100\n",
            "35/35 [==============================] - 125s 687ms/step\n",
            "\n",
            " Epoch 2/100\n",
            "35/35 [==============================] - 25s 707ms/step\n",
            "\n",
            " Epoch 3/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 4/100\n",
            "35/35 [==============================] - 24s 697ms/step\n",
            "\n",
            " Epoch 5/100\n",
            "35/35 [==============================] - 24s 698ms/step\n",
            "\n",
            " Epoch 6/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 7/100\n",
            "35/35 [==============================] - 24s 696ms/step\n",
            "\n",
            " Epoch 8/100\n",
            "35/35 [==============================] - 24s 698ms/step\n",
            "\n",
            " Epoch 9/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 10/100\n",
            "35/35 [==============================] - 25s 700ms/step\n",
            "\n",
            " Epoch 11/100\n",
            "35/35 [==============================] - 24s 698ms/step\n",
            "\n",
            " Epoch 12/100\n",
            "35/35 [==============================] - 24s 697ms/step\n",
            "\n",
            " Epoch 13/100\n",
            "35/35 [==============================] - 24s 700ms/step\n",
            "\n",
            " Epoch 14/100\n",
            "35/35 [==============================] - 24s 697ms/step\n",
            "\n",
            " Epoch 15/100\n",
            "35/35 [==============================] - 24s 700ms/step\n",
            "\n",
            " Epoch 16/100\n",
            "35/35 [==============================] - 25s 700ms/step\n",
            "\n",
            " Epoch 17/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 18/100\n",
            "35/35 [==============================] - 24s 700ms/step\n",
            "\n",
            " Epoch 19/100\n",
            "35/35 [==============================] - 24s 700ms/step\n",
            "\n",
            " Epoch 20/100\n",
            "35/35 [==============================] - 24s 700ms/step\n",
            "\n",
            " Epoch 21/100\n",
            "35/35 [==============================] - 24s 701ms/step\n",
            "\n",
            " Epoch 22/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 23/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 24/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 25/100\n",
            "35/35 [==============================] - 24s 707ms/step\n",
            "\n",
            " Epoch 26/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 27/100\n",
            "35/35 [==============================] - 25s 701ms/step\n",
            "\n",
            " Epoch 28/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 29/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 30/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 31/100\n",
            "35/35 [==============================] - 24s 702ms/step\n",
            "\n",
            " Epoch 32/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 33/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 34/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 35/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 36/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 37/100\n",
            "35/35 [==============================] - 25s 702ms/step\n",
            "\n",
            " Epoch 38/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 39/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 40/100\n",
            "35/35 [==============================] - 25s 703ms/step\n",
            "\n",
            " Epoch 41/100\n",
            "35/35 [==============================] - 24s 705ms/step\n",
            "\n",
            " Epoch 42/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 43/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 44/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 45/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 46/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 47/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 48/100\n",
            "35/35 [==============================] - 25s 706ms/step\n",
            "\n",
            " Epoch 49/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 50/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 51/100\n",
            "35/35 [==============================] - 24s 705ms/step\n",
            "\n",
            " Epoch 52/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 53/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 54/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 55/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 56/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 57/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 58/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 59/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 60/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 61/100\n",
            "35/35 [==============================] - 24s 705ms/step\n",
            "\n",
            " Epoch 62/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 63/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 64/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 65/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 66/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 67/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 68/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 69/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 70/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 71/100\n",
            "35/35 [==============================] - 24s 705ms/step\n",
            "\n",
            " Epoch 72/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 73/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 74/100\n",
            "35/35 [==============================] - 25s 704ms/step\n",
            "\n",
            " Epoch 75/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 76/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 77/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 78/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 79/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 80/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 81/100\n",
            "35/35 [==============================] - 24s 705ms/step\n",
            "\n",
            " Epoch 82/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 83/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 84/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 85/100\n",
            "35/35 [==============================] - 25s 706ms/step\n",
            "\n",
            " Epoch 86/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 87/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 88/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 89/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 90/100\n",
            "35/35 [==============================] - 25s 706ms/step\n",
            "\n",
            " Epoch 91/100\n",
            "35/35 [==============================] - 24s 706ms/step\n",
            "\n",
            " Epoch 92/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 93/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 94/100\n",
            "35/35 [==============================] - 25s 706ms/step\n",
            "\n",
            " Epoch 95/100\n",
            "35/35 [==============================] - 24s 709ms/step\n",
            "\n",
            " Epoch 96/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 97/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 98/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 99/100\n",
            "35/35 [==============================] - 25s 705ms/step\n",
            "\n",
            " Epoch 100/100\n",
            "35/35 [==============================] - 25s 706ms/step\n"
          ]
        }
      ],
      "source": [
        "train(train_data,EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rfZ6AcludBse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f6683-01fe-4500-a99a-5c1cd45259f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test_input, test_val, y_true= test_data.as_numpy_iterator().next()\n",
        "y_hat = siam_model.predict([test_input, test_val])\n",
        "[1 if prediction > 0.5 else 0 for prediction in y_hat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2HZV0l9pdBsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1daaf6-3078-45a5-ee3d-f89086cc710e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "m= Recall()\n",
        "m.update_state(y_true,y_hat)\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MkqOO9mIdBsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1329e8a2-4955-4a01-c04d-df7000d04055"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "m= Precision()\n",
        "m.update_state(y_true,y_hat)\n",
        "m.result().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N0w7qa5EdBsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bee55e8-ca0b-44b5-e902-6c0fa682f29c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "siam_model.save(path+'//'+'siamesemodelv2.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YrsCgc1pdBsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8194b5f-3808-40ab-b24c-d80681291b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# Reload model \n",
        "model = tf.keras.models.load_model(path+'//'+'siamesemodelv2.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HWDfTFc1dBsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d8acdf-ff7b-45a0-f48a-f2199c36a92b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4630629e-13],\n",
              "       [9.9999917e-01],\n",
              "       [1.0000000e+00],\n",
              "       [9.9977952e-01],\n",
              "       [1.0000000e+00],\n",
              "       [6.3462874e-11],\n",
              "       [4.6726263e-15],\n",
              "       [4.9249506e-12],\n",
              "       [7.3429670e-17],\n",
              "       [2.8252012e-08],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999619e-01],\n",
              "       [4.2344045e-08],\n",
              "       [3.2221343e-15],\n",
              "       [9.9999976e-01],\n",
              "       [3.9674058e-12]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.predict([test_input, test_val])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tBNBrwUMdBsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a389ab9-56a9-404e-9d74-f278760fdd6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SiameseNetwork\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
            "                                                                  'validation_img[0][0]']         \n",
            "                                                                                                  \n",
            " l1_dist_1 (L1Dist)             (None, 4096)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            4097        ['l1_dist_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "smGhWYv_dBsh"
      },
      "outputs": [],
      "source": [
        "def verify(frame ,model, detection_threshold,verification_threshold):\n",
        "    results=[]\n",
        "    for image in os.listdir(os.path.join(path+'//'+ 'application_data','verification_image')):\n",
        "        input_img = preprocess(os.path.join(path+'//'+ 'application_data','input_image','input_image.jpg'))\n",
        "        validation_img= preprocess(os.path.join(path+'//'+ 'application_data','verification_image',image))\n",
        "        \n",
        "        result= model.predict(list(np.expand_dims([input_img,validation_img],axis=1)))\n",
        "        results.append(result)\n",
        "    \n",
        "    detection=np.sum(np.array(results)>detection_threshold)\n",
        "    verification= detection / len(os.listdir(os.path.join(path+'//'+ 'application_data','verification_image')))\n",
        "    verified=verification > verification_threshold\n",
        "    return results,verified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gH7eLVmNdBsh"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret,frame=cap.read()\n",
        "    frame = frame[120:370,200:450,:] \n",
        "    cv2.imshow('Validation', frame)\n",
        "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
        "        cv2.imwrite(os.path.join(path+'//'+ 'application_data','input_image','input_image.jpg'),frame)\n",
        "        results, verified=verify(frame, model,0.9,0.7)\n",
        "        print(verified)\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}